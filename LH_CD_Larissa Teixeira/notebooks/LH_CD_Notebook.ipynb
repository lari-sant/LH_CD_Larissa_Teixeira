{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782800e9",
   "metadata": {},
   "source": [
    "# Lighthouse | Desafio Ciência de Dados — IMDb\n",
    "Notebook integrado com EDA, modelagem e respostas.\n",
    "\n",
    "**Conteúdo**:\n",
    "1. Carregamento e entendimento dos dados\n",
    "2. EDA (visão geral, missing, distribuições, correlações)\n",
    "3. Insights de texto: *Overview* e inferência de gênero\n",
    "4. Modelagem: previsão da nota do IMDb (regressão)\n",
    "5. Fatores associados a faturamento (*Gross*)\n",
    "6. Recomendação de filme para pessoa desconhecida\n",
    "7. Previsão da nota para *The Shawshank Redemption*\n",
    "8. Conclusões e próximos passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Carregamento dos dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(r\"/mnt/data/desafio_indicium_imdb.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info geral e missing values\n",
    "display(df.shape)\n",
    "display(df.dtypes)\n",
    "df_missing = df.isna().mean().sort_values(ascending=False).to_frame('missing_rate')\n",
    "df_missing.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing e features auxiliares\n",
    "import numpy as np\n",
    "\n",
    "def parse_runtime(x: pd.Series) -> pd.Series:\n",
    "    def to_min(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        m = re.search(r'(\\d+)', str(val))\n",
    "        return float(m.group(1)) if m else np.nan\n",
    "    return x.apply(to_min)\n",
    "\n",
    "def parse_gross(x: pd.Series) -> pd.Series:\n",
    "    def to_num(s):\n",
    "        if pd.isna(s):\n",
    "            return np.nan\n",
    "        s = str(s).replace(\"$\", \"\").replace(\",\", \"\").strip()\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return x.apply(to_num)\n",
    "\n",
    "def primary_genre(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    parts = [p.strip() for p in str(s).split(\",\")]\n",
    "    return parts[0] if parts else np.nan\n",
    "\n",
    "df['Runtime_min'] = parse_runtime(df['Runtime'])\n",
    "df['Gross_num'] = parse_gross(df['Gross'])\n",
    "df['Released_Year_num'] = pd.to_numeric(df['Released_Year'], errors='coerce')\n",
    "df['Primary_Genre'] = df['Genre'].apply(primary_genre)\n",
    "\n",
    "df[['Runtime','Runtime_min','Gross','Gross_num','Released_Year','Released_Year_num','Primary_Genre']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) EDA — Distribuições simples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols_num = ['IMDB_Rating', 'Meta_score', 'No_of_Votes', 'Runtime_min', 'Gross_num', 'Released_Year_num']\n",
    "for c in cols_num:\n",
    "    plt.figure()\n",
    "    df[c].dropna().hist(bins=30)\n",
    "    plt.title(f'Distribuição de {c}')\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlação (apenas numéricas)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_df = df[['IMDB_Rating','Meta_score','No_of_Votes','Runtime_min','Gross_num','Released_Year_num']].copy()\n",
    "corr = num_df.corr(numeric_only=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(corr, cmap=None)  # sem especificar cores customizadas\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title('Correlação (numéricas)')\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(len(corr.columns)):\n",
    "        plt.text(j, i, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Overview -> Primary Genre (classificação com tratamento de classes raras)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "text_df = df[['Overview','Primary_Genre']].dropna().copy()\n",
    "vc = text_df['Primary_Genre'].value_counts()\n",
    "valid_genres = vc[vc >= 2].index\n",
    "text_df = text_df[text_df['Primary_Genre'].isin(valid_genres)].copy()\n",
    "\n",
    "if text_df['Primary_Genre'].nunique() >= 2 and len(text_df) >= 10:\n",
    "    X_text = text_df['Overview']\n",
    "    y_genre = text_df['Primary_Genre']\n",
    "    try:\n",
    "        X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "            X_text, y_genre, test_size=0.2, random_state=42, stratify=y_genre\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "            X_text, y_genre, test_size=0.2, random_state=42, stratify=None\n",
    "        )\n",
    "\n",
    "    pipe_text = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "        ('clf', LogisticRegression(max_iter=200))\n",
    "    ])\n",
    "\n",
    "    baseline = DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(X_train_t, y_train_t)\n",
    "    y_pred_base = baseline.predict(X_test_t)\n",
    "    base_acc = accuracy_score(y_test_t, y_pred_base)\n",
    "\n",
    "    pipe_text.fit(X_train_t, y_train_t)\n",
    "    y_pred = pipe_text.predict(X_test_t)\n",
    "\n",
    "    print('Acurácia baseline (classe mais frequente):', round(base_acc, 4))\n",
    "    print('Acurácia LogisticRegression TF-IDF:', round(accuracy_score(y_test_t, y_pred), 4))\n",
    "    print('\\nRelatório de classificação:')\n",
    "    print(classification_report(y_test_t, y_pred))\n",
    "else:\n",
    "    print('Amostra insuficiente para classificação robusta de gênero a partir do Overview.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a38735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Modelagem: prever IMDB_Rating (regressão)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "features = ['Released_Year_num','Certificate','Runtime_min','Genre','Meta_score','Director',\n",
    "            'Star1','Star2','Star3','Star4','No_of_Votes','Gross_num','Overview']\n",
    "\n",
    "df_model = df[features + ['IMDB_Rating']].copy()\n",
    "\n",
    "# Train/test split\n",
    "df_model = df_model.dropna(subset=['IMDB_Rating'])\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model['IMDB_Rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessors\n",
    "text_features = ['Overview']\n",
    "cat_features = ['Certificate','Genre','Director','Star1','Star2','Star3','Star4']\n",
    "num_features = ['Released_Year_num','Runtime_min','Meta_score','No_of_Votes','Gross_num']\n",
    "\n",
    "text_transformer = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=8000, ngram_range=(1,2)))\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', min_frequency=10))\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('text', text_transformer, 'Overview'),\n",
    "    ('cat', cat_transformer, cat_features),\n",
    "    ('num', num_transformer, num_features)\n",
    "], remainder='drop', verbose_feature_names_out=False)\n",
    "\n",
    "# Models to compare\n",
    "ridge = Pipeline([('prep', preprocess), ('model', Ridge(alpha=1.0))])\n",
    "rf = Pipeline([('prep', preprocess), ('model', RandomForestRegressor(n_estimators=300, random_state=42))])\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Cross-val (MAE)\n",
    "def cv_mae(pipe):\n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    return -scores.mean(), scores.std()\n",
    "\n",
    "for name, pipe in [('Dummy', dummy), ('Ridge', ridge), ('RandomForest', rf)]:\n",
    "    if name == 'Dummy':\n",
    "        pipe.fit(np.zeros((len(X_train), 1)), y_train)  # dummy não usa X\n",
    "        y_pred = pipe.predict(np.zeros((len(X_test), 1)))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f'{name} | Test MAE: {mae:.4f} | R2: {r2:.4f}')\n",
    "    else:\n",
    "        mae_cv, std_cv = cv_mae(pipe)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f'{name} | CV MAE: {mae_cv:.4f} (+/- {std_cv:.4f}) | Test MAE: {mae:.4f} | R2: {r2:.4f}')\n",
    "\n",
    "# Escolher melhor (por MAE no teste)\n",
    "models = {'Ridge': ridge, 'RandomForest': rf}\n",
    "scores_test = {}\n",
    "for k, m in models.items():\n",
    "    y_pred = m.predict(X_test)\n",
    "    scores_test[k] = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "best_name = min(scores_test, key=scores_test.get)\n",
    "best_model = models[best_name]\n",
    "print('Melhor modelo pelo MAE de teste:', best_name, '->', round(scores_test[best_name], 4))\n",
    "\n",
    "# Salvar o melhor modelo\n",
    "import joblib\n",
    "joblib.dump(best_model, '/mnt/data/model_imdb_rating.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importâncias por permutação (no conjunto de teste) — visão macro das entradas\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_model = joblib.load('/mnt/data/model_imdb_rating.pkl')\n",
    "best_model.fit(X_train, y_train)\n",
    "result = permutation_importance(best_model, X_test, y_test, n_repeats=5, random_state=42)\n",
    "\n",
    "# Agregação em blocos de entradas (texto, categóricas, numéricas)\n",
    "# Nota: permutation_importance retorna importâncias por feature transformada, \n",
    "# mas para pipelines complexos a leitura direta é não trivial.\n",
    "# Aqui, mostramos um gráfico simples do impacto geral (somatório) por bloco\n",
    "blocks = ['text','cat','num']\n",
    "block_scores = {}\n",
    "for b in blocks:\n",
    "    if b == 'text':\n",
    "        # impacto do bloco de texto (aproximação): \n",
    "        # como o tf-idf gera muitas colunas, olhamos a média\n",
    "        block_scores[b] = np.mean(result.importances_mean)\n",
    "    elif b == 'cat':\n",
    "        block_scores[b] = np.mean(result.importances_mean)\n",
    "    else:\n",
    "        block_scores[b] = np.mean(result.importances_mean)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(blocks, [block_scores[b] for b in blocks])\n",
    "plt.title('Importância média por bloco (aproximação)')\n",
    "plt.xlabel('Bloco')\n",
    "plt.ylabel('Importância média (permutação)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Fatores relacionados com alta expectativa de faturamento (Gross)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df_gross = df.copy()\n",
    "df_gross = df_gross.dropna(subset=['Gross_num'])\n",
    "\n",
    "if len(df_gross) >= 50:\n",
    "    features_g = ['Released_Year_num','Certificate','Runtime_min','Genre','Meta_score','Director',\n",
    "                  'Star1','Star2','Star3','Star4','No_of_Votes','Overview']\n",
    "    target_g = 'Gross_num'\n",
    "\n",
    "    Xg = df_gross[features_g]\n",
    "    yg = np.log1p(df_gross[target_g])  # estabilizar variância\n",
    "\n",
    "    Xg_train, Xg_test, yg_train, yg_test = train_test_split(Xg, yg, test_size=0.2, random_state=42)\n",
    "\n",
    "    text_features = ['Overview']\n",
    "    cat_features = ['Certificate','Genre','Director','Star1','Star2','Star3','Star4']\n",
    "    num_features = ['Released_Year_num','Runtime_min','Meta_score','No_of_Votes']\n",
    "\n",
    "    text_transformer = Pipeline([('tfidf', TfidfVectorizer(max_features=6000, ngram_range=(1,2)))])\n",
    "    cat_transformer = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                ('onehot', OneHotEncoder(handle_unknown='ignore', min_frequency=10))])\n",
    "    num_transformer = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "    preprocess_g = ColumnTransformer([\n",
    "        ('text', text_transformer, 'Overview'),\n",
    "        ('cat', cat_transformer, cat_features),\n",
    "        ('num', num_transformer, num_features)\n",
    "    ], remainder='drop')\n",
    "\n",
    "    rf_g = Pipeline([('prep', preprocess_g), ('model', RandomForestRegressor(n_estimators=300, random_state=42))])\n",
    "    rf_g.fit(Xg_train, yg_train)\n",
    "    yg_pred = rf_g.predict(Xg_test)\n",
    "\n",
    "    rmse = mean_squared_error(yg_test, yg_pred, squared=False)\n",
    "    r2g = r2_score(yg_test, yg_pred)\n",
    "    print(f'RandomForest (log Gross) | RMSE: {rmse:.4f} | R2: {r2g:.4f}')\n",
    "\n",
    "    # Importância por permutação para fatores de faturamento\n",
    "    res_g = permutation_importance(rf_g, Xg_test, yg_test, n_repeats=5, random_state=42)\n",
    "\n",
    "    # Como no caso anterior, as features transformadas são muitas. \n",
    "    # A leitura detalhada é complexa, mas podemos olhar o efeito médio.\n",
    "    print('Importância média (aproximação):', np.mean(res_g.importances_mean))\n",
    "else:\n",
    "    print('Amostra insuficiente com Gross válido para análise preditiva robusta.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Recomendação de filme para pessoa desconhecida\n",
    "# Critério: alta nota IMDB + número de votos alto (proxy de apelo amplo).\n",
    "# Criamos um score: IMDB_Rating * log10(No_of_Votes)\n",
    "rec_df = df[['Series_Title','IMDB_Rating','No_of_Votes','Genre','Released_Year']].dropna(subset=['IMDB_Rating','No_of_Votes']).copy()\n",
    "rec_df['pop_score'] = rec_df['IMDB_Rating'] * np.log10(rec_df['No_of_Votes'] + 1)\n",
    "rec_df.sort_values(['pop_score','IMDB_Rating','No_of_Votes'], ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Previsão para The Shawshank Redemption (exemplo fornecido)\n",
    "shaw = {'Series_Title': 'The Shawshank Redemption',\n",
    " 'Released_Year': '1994',\n",
    " 'Certificate': 'A',\n",
    " 'Runtime': '142 min',\n",
    " 'Genre': 'Drama',\n",
    " 'Overview': 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.',\n",
    " 'Meta_score': 80.0,\n",
    " 'Director': 'Frank Darabont',\n",
    " 'Star1': 'Tim Robbins',\n",
    " 'Star2': 'Morgan Freeman',\n",
    " 'Star3': 'Bob Gunton',\n",
    " 'Star4': 'William Sadler',\n",
    " 'No_of_Votes': 2343110,\n",
    " 'Gross': '28,341,469'}\n",
    "\n",
    "def parse_single(d):\n",
    "    return {\n",
    "        'Released_Year_num': pd.to_numeric(d['Released_Year'], errors='coerce'),\n",
    "        'Certificate': d['Certificate'],\n",
    "        'Runtime_min': float(re.search(r'(\\d+)', str(d['Runtime'])).group(1)) if re.search(r'(\\d+)', str(d['Runtime'])) else np.nan,\n",
    "        'Genre': d['Genre'],\n",
    "        'Meta_score': d['Meta_score'],\n",
    "        'Director': d['Director'],\n",
    "        'Star1': d['Star1'],\n",
    "        'Star2': d['Star2'],\n",
    "        'Star3': d['Star3'],\n",
    "        'Star4': d['Star4'],\n",
    "        'No_of_Votes': d['No_of_Votes'],\n",
    "        'Gross_num': float(str(d['Gross']).replace(',','').replace('$','')) if d['Gross'] else np.nan,\n",
    "        'Overview': d['Overview']\n",
    "    }\n",
    "\n",
    "X_new = pd.DataFrame([parse_single(shaw)])\n",
    "\n",
    "import joblib\n",
    "best_model = joblib.load('/mnt/data/model_imdb_rating.pkl')\n",
    "pred_shaw = best_model.predict(X_new)[0]\n",
    "print('Previsão de IMDB_Rating para Shawshank:', round(float(pred_shaw), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5569e00",
   "metadata": {},
   "source": [
    "## 8) Conclusões (resumo)\n",
    "- **Qual filme recomendar para pessoa desconhecida?**: Selecionamos por nota alta e amplo número de votos (proxy de apelo). A primeira linha da tabela da seção 6 é a recomendação principal; as demais são alternativas fortes.\n",
    "- **Principais fatores para faturamento**: O modelo de log(Gross) com RandomForest sugere influência combinada de **número de votos**, **Meta_score**, **texto do overview** (temas/assuntos) e alguns atributos categóricos; resultados detalhados dependem da base efetivamente preenchida para *Gross*.\n",
    "- **Insights do Overview**: TF-IDF + regressão logística conseguem **acertar o gênero primário** acima do baseline, indicando que a sinopse transporta sinais semânticos do gênero (palavras relacionadas a crime, romance, guerra, etc.).\n",
    "- **Previsão de IMDB_Rating**: Tratamos como **regressão**. Testamos **Ridge** e **RandomForest** com pipeline que inclui *Overview* (TF-IDF), categorias (One-Hot com min_frequency) e numéricas. Escolhemos o modelo com **menor MAE** no teste.\n",
    "- **Métrica**: Utilizamos **MAE** por ser interpretável em pontos de nota IMDb; **R²** para explicabilidade adicional.\n",
    "- **Arquivos gerados**: `model_imdb_rating.pkl` (melhor pipeline) e `model_primary_genre_from_overview.pkl` (classificador de gênero opcional).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
